import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
import random
import pickle
import os
import re
from datetime import datetime
import glob

# ==========================================
# [ì„¤ì •]
# ==========================================
# ì…ë ¥ íŒŒì¼ íŒ¨í„´ (data/twitter í´ë” ë‚´ì˜ íŒŒì¼ ê²€ìƒ‰)
INPUT_FILE_PATTERN = "/Users/leejongmin/code/ë¹„ëª¨/twitter_tech_filtered_20251212_1627.csv" # ê¸°ë³¸ íŒ¨í„´ ë³€ê²½
COOKIE_FILE = "twitter_cookies.pkl"

# [Anti-Ban ì„¤ì •]
MIN_SLEEP = 4.0        # ìµœì†Œ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
MAX_SLEEP = 8.0        # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
LONG_SLEEP_EVERY = 20  # Nëª…ë§ˆë‹¤ ê¸¸ê²Œ íœ´ì‹
LONG_SLEEP_DURATION = (30, 60) # ê¸´ íœ´ì‹ ì‹œê°„ ë²”ìœ„ (ì´ˆ)

# ==========================================
# ìœ í‹¸ë¦¬í‹°
# ==========================================
def random_sleep(min_t=MIN_SLEEP, max_t=MAX_SLEEP):
    time.sleep(random.uniform(min_t, max_t))

def load_cookies(driver, filename):
    if not os.path.exists(filename): return False
    try:
        with open(filename, "rb") as file:
            cookies = pickle.load(file)
            for cookie in cookies: driver.add_cookie(cookie)
        return True
    except: return False

def parse_number_k(text):
    if not text: return 0
    text = str(text).replace(',', '').strip()
    try:
        if 'K' in text: return int(float(text.replace('K', '')) * 1000)
        if 'M' in text: return int(float(text.replace('M', '')) * 1000000)
        if 'ë§Œ' in text: return int(float(text.replace('ë§Œ', '')) * 10000)
        nums = re.findall(r'[\d\.]+', text)
        if nums: return int(float(nums[0]))
        return 0
    except: return 0

def get_latest_input_file():
    # 1. data/twitter í´ë” ê²€ìƒ‰
    files = glob.glob(INPUT_FILE_PATTERN)
    
    # 2. ì—†ìœ¼ë©´ ë£¨íŠ¸ í´ë” ê²€ìƒ‰ (í•˜ìœ„ í˜¸í™˜ì„±)
    if not files:
        files = glob.glob("data/twitter/twitter_tech_filtered_*.csv")
        
    if not files: return None
    return max(files, key=os.path.getctime)

# ==========================================
# í¬ë¡¤ë§ ë¡œì§
# ==========================================
def get_follower_count(driver, username):
    url = f"https://x.com/{username}"
    print(f"   [Visiting] {url}")
    
    # [Retry Logic] ë¡œë”© ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 2íšŒ ì¬ì‹œë„ (Backoff ì ìš©)
    for attempt in range(2):
        try:
            driver.get(url)
            
            # í”„ë¡œí•„ ë¡œë”© ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆë¡œ ì¦ê°€)
            try:
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-testid="UserName"]'))
                )
            except:
                # ë¡œë”© ì‹¤íŒ¨ ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                print(f"      -> âš ï¸ ë¡œë”© ì§€ì—° (ì‹œë„ {attempt+1}/2)")
                time.sleep(5 * (attempt + 1))
                continue

            random_sleep(1.5, 2.5)
            
            # íŒ”ë¡œì›Œ ìˆ˜ ì¶”ì¶œ
            try:
                # 1. /verified_followers
                selector = f'a[href="/{username}/verified_followers"] span'
                elem = driver.find_element(By.CSS_SELECTOR, selector)
                return parse_number_k(elem.text)
            except:
                try:
                    # 2. /followers
                    selector = f'a[href="/{username}/followers"] span'
                    elem = driver.find_element(By.CSS_SELECTOR, selector)
                    return parse_number_k(elem.text)
                except:
                    # 3. í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ Regexë¡œ ì°¾ê¸° (Fallback)
                    try:
                        src = driver.page_source
                        # "followers_count": 1234
                        match = re.search(r'"followers_count":\s*(\d+)', src)
                        if match: return int(match.group(1))
                    except: pass
                    
                    print("      -> âš ï¸ íŒ”ë¡œì›Œ ìˆ˜ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    return 0
            
            # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ
            break
            
        except Exception as e:
            print(f"      -> [Error] {e}")
            time.sleep(3)
            
    return -1 # ê²°êµ­ ì‹¤íŒ¨í•¨

# ==========================================
# ë©”ì¸
# ==========================================
def main():
    input_file = get_latest_input_file()
    if not input_file:
        print(f"[Error] ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒ¨í„´: {INPUT_FILE_PATTERN}")
        return
    
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {input_file}")
    
    try:
        df = pd.read_csv(input_file)
        if 'author_id' not in df.columns:
            print("[Error] 'author_id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        # follower_count ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if 'follower_count' not in df.columns:
            df['follower_count'] = -1
            print("   -> 'follower_count' ì»¬ëŸ¼ ì¶”ê°€ë¨")
            
        # author_id ì •ë¦¬
        df['author_id_clean'] = df['author_id'].astype(str).apply(lambda x: x.replace('@', '').strip())
        
        # ìˆ˜ì§‘ ëŒ€ìƒ: follower_countê°€ ì—†ê±°ë‚˜ -1ì¸ ìœ ì €
        # ì´ë¯¸ ìˆ˜ì§‘ëœ ìœ ì €ëŠ” ê±´ë„ˆëœ€
        users_to_crawl = df[df['follower_count'] == -1]['author_id_clean'].unique().tolist()
        users_to_crawl = [u for u in users_to_crawl if u]
        
        print(f"   -> ì´ {len(df['author_id_clean'].unique())}ëª…ì˜ ìœ ì € ì¤‘ {len(users_to_crawl)}ëª… ìˆ˜ì§‘ ì˜ˆì •")
        
        if not users_to_crawl:
            print("   -> ëª¨ë“  ìœ ì €ì˜ íŒ”ë¡œì›Œ ì •ë³´ê°€ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤.")
            return

    except Exception as e:
        print(f"[Error] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return

# ==========================================
# ë“œë¼ì´ë²„ ì„¤ì •
# ==========================================
def init_driver():
    print("ğŸ”§ ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì¤‘...")
    options = uc.ChromeOptions()
    options.add_argument('--no-first-run')
    options.add_argument('--blink-settings=imagesEnabled=false')
    
    try:
        driver = uc.Chrome(options=options)
        driver.get("https://x.com")
        
        if load_cookies(driver, COOKIE_FILE):
            driver.refresh()
            print("ğŸª ì¿ í‚¤ ë¡œë“œ ì™„ë£Œ")
            random_sleep(3, 5)
        else:
            print("âš ï¸ ì¿ í‚¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œê·¸ì¸ ìƒíƒœê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            random_sleep(2, 3)
            
        return driver
    except Exception as e:
        print(f"[Error] ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

# ==========================================
# ë©”ì¸
# ==========================================
def main():
    input_file = get_latest_input_file()
    if not input_file:
        print(f"[Error] ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒ¨í„´: {INPUT_FILE_PATTERN}")
        return
    
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {input_file}")
    
    try:
        df = pd.read_csv(input_file)
        if 'author_id' not in df.columns:
            print("[Error] 'author_id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        # follower_count ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if 'follower_count' not in df.columns:
            df['follower_count'] = -1
            print("   -> 'follower_count' ì»¬ëŸ¼ ì¶”ê°€ë¨")
            
        # author_id ì •ë¦¬
        df['author_id_clean'] = df['author_id'].astype(str).apply(lambda x: x.replace('@', '').strip())
        
        # ìˆ˜ì§‘ ëŒ€ìƒ: follower_countê°€ ì—†ê±°ë‚˜ -1ì¸ ìœ ì €
        users_to_crawl = df[df['follower_count'] == -1]['author_id_clean'].unique().tolist()
        users_to_crawl = [u for u in users_to_crawl if u]
        
        print(f"   -> ì´ {len(df['author_id_clean'].unique())}ëª…ì˜ ìœ ì € ì¤‘ {len(users_to_crawl)}ëª… ìˆ˜ì§‘ ì˜ˆì •")
        
        if not users_to_crawl:
            print("   -> ëª¨ë“  ìœ ì €ì˜ íŒ”ë¡œì›Œ ì •ë³´ê°€ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤.")
            return

    except Exception as e:
        print(f"[Error] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return

    driver = init_driver()
    if not driver: return

    try:
        print("="*60)
        print(f"ğŸš€ ìœ ì € íŒ”ë¡œì›Œ ìˆ˜ì§‘ ì‹œì‘ ({len(users_to_crawl)}ëª…)")
        print(f"   - ê¸°ë³¸ ëŒ€ê¸°: {MIN_SLEEP}~{MAX_SLEEP}ì´ˆ")
        print(f"   - ê¸´ íœ´ì‹: {LONG_SLEEP_EVERY}ëª…ë§ˆë‹¤ {LONG_SLEEP_DURATION}ì´ˆ")
        print("="*60)
        
        consecutive_failures = 0
        MAX_CONSECUTIVE_FAILURES = 3
        
        for idx, user in enumerate(users_to_crawl, 1):
            print(f"[{idx}/{len(users_to_crawl)}] @{user}")
            
            try:
                followers = get_follower_count(driver, user)
                
                if followers != -1:
                    df.loc[df['author_id_clean'] == user, 'follower_count'] = followers
                    consecutive_failures = 0 # ì„±ê³µ ì‹œ ì´ˆê¸°í™”
                else:
                    consecutive_failures += 1
                    print(f"   -> âš ï¸ ì‹¤íŒ¨ (ì—°ì† {consecutive_failures}íšŒ)")

            except Exception as e:
                print(f"   -> [Critical Error] í¬ë¡¤ë§ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                consecutive_failures += 1
            
            # ì—°ì† ì‹¤íŒ¨ê°€ ë§ìœ¼ë©´ ë“œë¼ì´ë²„ ì¬ì‹œì‘
            if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
                print(f"   ğŸš¨ ì—°ì† {consecutive_failures}íšŒ ì‹¤íŒ¨ ë˜ëŠ” ì˜¤ë¥˜. ë“œë¼ì´ë²„ ì¬ì‹œì‘...")
                try:
                    driver.quit()
                except: pass
                
                time.sleep(10) # ì ì‹œ ëŒ€ê¸°
                driver = init_driver()
                if not driver:
                    print("   -> [Fatal] ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                consecutive_failures = 0
                continue

            # ì¤‘ê°„ ì €ì¥
            if idx % 10 == 0:
                save_df = df.drop(columns=['author_id_clean'])
                save_df.to_csv(input_file, index=False, encoding='utf-8-sig')
                print(f"   -> ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ (ì§„í–‰ë¥ : {idx}/{len(users_to_crawl)})")
            
            # [Anti-Ban] ê¸´ íœ´ì‹
            if idx % LONG_SLEEP_EVERY == 0:
                sleep_time = random.uniform(*LONG_SLEEP_DURATION)
                print(f"   ğŸ’¤ {LONG_SLEEP_EVERY}ëª… ìˆ˜ì§‘ ì™„ë£Œ. {int(sleep_time)}ì´ˆ íœ´ì‹...")
                time.sleep(sleep_time)
            else:
                random_sleep()
            
        # ìµœì¢… ì €ì¥
        save_df = df.drop(columns=['author_id_clean'])
        save_df.to_csv(input_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ‰ ì™„ë£Œ! íŒŒì¼ ì—…ë°ì´íŠ¸ë¨.\nğŸ“ {input_file}")
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨. í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©ì„ ì €ì¥í•©ë‹ˆë‹¤.")
        save_df = df.drop(columns=['author_id_clean'])
        save_df.to_csv(input_file, index=False, encoding='utf-8-sig')
        print("   -> ğŸ’¾ ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        print(f"\n[Fatal Error] ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        save_df = df.drop(columns=['author_id_clean'])
        save_df.to_csv(input_file, index=False, encoding='utf-8-sig')
        print("   -> ğŸ’¾ ë¹„ìƒ ì €ì¥ ì™„ë£Œ")
        
    finally:
        if driver:
            try: driver.quit()
            except: pass

if __name__ == "__main__":
    main()
