import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
import random
import os
from datetime import datetime
from itertools import combinations
import re

# ==========================================
# [ì„¤ì •] íŒŒì¼ ì…ë ¥ ë° ìˆ˜ì§‘ ì„¤ì •
# ==========================================
# [ì¤‘ìš”] 1ë²ˆ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë§Œë“  íŒŒì¼ëª…ì„ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”
INPUT_KEYWORD_FILE = "gemini_trend_keywords_20251129_1301.csv"  # <-- íŒŒì¼ëª… ìˆ˜ì • í•„ìš”

VIDEOS_PER_KEYWORD = 10      # í‚¤ì›Œë“œë‹¹ ìˆ˜ì§‘í•  ì˜ìƒ ìˆ˜
COMMENTS_PER_VIDEO = 100     # ì˜ìƒë‹¹ ìˆ˜ì§‘í•  ëŒ“ê¸€ ìˆ˜
MIN_COMMENT_LENGTH = 15     # 15ì ë¯¸ë§Œ ëŒ“ê¸€ í•„í„°ë§ (í’ˆì§ˆ ê´€ë¦¬)

# í‚¤ì›Œë“œ ì¡°í•© ì„¤ì •
USE_COMBINATION = False     # Trueë©´ ì¡°í•© ì‚¬ìš©, Falseë©´ ì›ë³¸ í‚¤ì›Œë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
COMBINATION_SIZE = 2        # í‚¤ì›Œë“œ ì¡°í•© ê°œìˆ˜ (USE_COMBINATION=Trueì¼ ë•Œë§Œ ì‚¬ìš©)
MAX_COMBINATIONS = 50       # ìµœëŒ€ ì¡°í•© ê°œìˆ˜ (ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼)

# ==========================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def random_sleep(min_t=2.0, max_t=4.0):
    time.sleep(random.uniform(min_t, max_t))

def scroll_down(driver, count=3):
    body = driver.find_element(By.TAG_NAME, "body")
    for _ in range(count):
        body.send_keys(Keys.PAGE_DOWN)
        time.sleep(random.uniform(1.0, 2.0))

def combine_keywords(keywords, combination_size=2, max_combinations=50):
    """
    í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ë” êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ ìƒì„±
    ì˜ˆ: ['AI', 'Python', 'ML'] -> 'AI Python', 'AI ML', 'Python ML'
    """
    all_combos = list(combinations(keywords, combination_size))
    # ë„ˆë¬´ ë§ìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§
    if len(all_combos) > max_combinations:
        all_combos = random.sample(all_combos, max_combinations)
    
    # ì¡°í•©ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°
    combined_keywords = [' '.join(combo) for combo in all_combos]
    random.shuffle(combined_keywords)
    return combined_keywords

def parse_number_k(text):
    """
    '1.2ë§ŒíšŒ', '500K', '1.5M', '70,454íšŒ' ë“±ì„ ìˆ«ìë¡œ ë³€í™˜
    """
    if not text: return 0
    text = text.replace(',', '').replace('íšŒ', '').replace('views', '').replace('subscribers', '').replace('êµ¬ë…ì', '').replace('ëª…', '').strip()
    try:
        if 'ë§Œ' in text:
            return int(float(text.replace('ë§Œ', '')) * 10000)
        if 'ì–µ' in text:
            return int(float(text.replace('ì–µ', '')) * 100000000)
        if 'K' in text or 'ì²œ' in text: # ì˜ë¬¸ K or í•œê¸€ ì²œ
             return int(float(text.replace('K', '').replace('ì²œ', '')) * 1000)
        if 'M' in text or 'ë°±ë§Œ' in text:
            return int(float(text.replace('M', '').replace('ë°±ë§Œ', '')) * 1000000)
        
        # ìˆ«ìë§Œ ë‚¨ê¸°ê¸°
        nums = re.findall(r'[\d\.]+', text)
        if nums:
            return int(float(nums[0]))
        return 0
    except:
        return 0

# ==========================================
# ìœ íŠœë¸Œ í¬ë¡¤ë§ í•¨ìˆ˜ë“¤
# ==========================================
def get_video_links(driver, keyword, limit=3):
    print(f"\n[ğŸ” Search] '{keyword}'")
    try:
        # sp=CAMSAhAB: ì¡°íšŒìˆ˜ ìˆœ ì •ë ¬ (ë…¼ìŸ ë§ì€ ì˜ìƒ íƒ€ê²ŸíŒ…)
        search_url = f"https://www.youtube.com/results?search_query={keyword}&sp=CAMSAhAB"
        
        try:
            driver.get(search_url)
        except Exception as e:
            print(f"   [Warning] ê²€ìƒ‰ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨ (Timeout ë“±): {e}")
            return []
            
        random_sleep(3, 5)
        
        links = []
        titles = []
        
        scroll_down(driver, 2)
        videos = driver.find_elements(By.CSS_SELECTOR, 'ytd-video-renderer')
        
        for video in videos:
            if len(links) >= limit: break
            try:
                a_tag = video.find_element(By.ID, "video-title")
                link = a_tag.get_attribute("href")
                title = a_tag.get_attribute("title")
                
                # Shorts ì œì™¸, ì¼ë°˜ ì˜ìƒë§Œ
                if "/watch?v=" in link:
                    links.append(link)
                    titles.append(title)
            except: continue
        return list(zip(titles, links))
    except: return []

def get_video_description(driver):
    try:
        try:
            driver.find_element(By.CSS_SELECTOR, "#expand").click()
            time.sleep(1)
        except: pass
        return driver.find_element(By.CSS_SELECTOR, "#description-inline-expander").text
    except: return ""

def get_video_metadata(driver):
    """ì˜ìƒ ê²Œì‹œì¼, ì¢‹ì•„ìš” ìˆ˜, ì¡°íšŒìˆ˜, êµ¬ë…ì ìˆ˜ ìˆ˜ì§‘"""
    metadata = {
        'video_published_date': None,
        'video_likes': 0,
        'video_views': 0,
        'channel_subscribers': 0
    }
    
    # [Wait] ë©”íƒ€ë°ì´í„°ê°€ ë¡œë“œë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ)
    try:
        WebDriverWait(driver, 5).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "#info span, #info-strings yt-formatted-string"))
        )
    except: pass

    # 1. ì˜ìƒ ê²Œì‹œì¼ & ì¡°íšŒìˆ˜ (UI Scraping + Retry)
    for attempt in range(3):
        try:
            info_elements = driver.find_elements(By.CSS_SELECTOR, "#info span, yt-formatted-string#info span, #info-text span")
            for span in info_elements:
                text = span.text.strip()
                if not text: continue
                
                if ("ì¡°íšŒìˆ˜" in text or "views" in text) and metadata['video_views'] == 0:
                    metadata['video_views'] = parse_number_k(text)
                elif ("ì „" in text or "ago" in text or "202" in text) and not metadata['video_published_date']:
                    if "ìŠ¤íŠ¸ë¦¬ë°" in text: continue 
                    metadata['video_published_date'] = text
            
            if metadata['video_views'] > 0: break
            time.sleep(1.5)
        except: 
            time.sleep(1)
            pass

    # [Fallback] ì¡°íšŒìˆ˜ê°€ ì—¬ì „íˆ 0ì´ë©´ ì†ŒìŠ¤ ì½”ë“œì—ì„œ Regexë¡œ ì¶”ì¶œ (ê°€ì¥ ê°•ë ¥í•œ ë°©ë²•)
    if metadata['video_views'] == 0:
        try:
            page_source = driver.page_source
            # íŒ¨í„´ 1: "viewCount":"12345"
            match1 = re.search(r'"viewCount":"(\d+)"', page_source)
            if match1:
                metadata['video_views'] = int(match1.group(1))
            else:
                # íŒ¨í„´ 2: "originalViewCount":"12345"
                match2 = re.search(r'"originalViewCount":"(\d+)"', page_source)
                if match2:
                    metadata['video_views'] = int(match2.group(1))
                else:
                    # íŒ¨í„´ 3: "viewCount":{"simpleText":"ì¡°íšŒìˆ˜ 1.2ë§ŒíšŒ"}
                    match3 = re.search(r'"viewCount":\{"simpleText":"(.*?)"\}', page_source)
                    if match3:
                        metadata['video_views'] = parse_number_k(match3.group(1))
        except: pass

    # 2. ì¢‹ì•„ìš” ìˆ˜
    try:
        like_selectors = [
            ".yt-spec-button-shape-next__button-text-content",
            "like-button-view-model button",
            "button[aria-label*='ì¢‹ì•„ìš”']",
            "yt-button-shape button[aria-label*='ì¢‹ì•„ìš”']",
            "#segmented-like-button button"
        ]
        for selector in like_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in elements:
                    text = elem.text.strip()
                    if text and (text.isdigit() or 'ì²œ' in text or 'ë§Œ' in text or 'K' in text or 'M' in text):
                         val = parse_number_k(text)
                         if val > 0:
                             metadata['video_likes'] = val
                             break
                    aria_label = elem.get_attribute("aria-label")
                    if aria_label and ('ì¢‹ì•„ìš”' in aria_label or 'like' in aria_label.lower()):
                        val = parse_number_k(aria_label)
                        if val > 0:
                            metadata['video_likes'] = val
                            break
                if metadata['video_likes'] > 0: break
            except: continue
    except: pass

    # 3. ì¡°íšŒìˆ˜ (Views) - Fallback (Specific Renderers)
    if metadata['video_views'] == 0:
        try:
            view_selectors = [
                "ytd-video-view-count-renderer span.view-count",
                "#info-container yt-formatted-string span:nth-child(1)", 
                "ytd-watch-metadata #description-inner #info span"
            ]
            for selector in view_selectors:
                try:
                    view_elem = driver.find_element(By.CSS_SELECTOR, selector)
                    text = view_elem.text
                    if "ì¡°íšŒìˆ˜" in text or "views" in text:
                        metadata['video_views'] = parse_number_k(text)
                        break
                except: continue
        except: pass

    # 4. êµ¬ë…ì ìˆ˜ (Subscribers)
    try:
        sub_selectors = [
            "#owner-sub-count",
            "yt-formatted-string#owner-sub-count"
        ]
        for selector in sub_selectors:
            try:
                sub_elem = driver.find_element(By.CSS_SELECTOR, selector)
                text = sub_elem.text # "êµ¬ë…ì 100ë§Œëª…"
                if text:
                    metadata['channel_subscribers'] = parse_number_k(text)
                    break
            except: continue
    except: pass
    
    return metadata

def get_comments_from_video(driver, title, url, limit=30):
    print(f"   [Mining] {title[:20]}...")
    try:
        driver.get(url)
    except Exception as e:
        print(f"   [Warning] ì˜ìƒ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨ (Timeout ë“±): {e}")
        return []
        
    random_sleep(3, 5) # [Wait] Increased wait time for metadata loading
    collected = []
    
    # 0. ì˜ìƒ ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (ê²Œì‹œì¼, ì¢‹ì•„ìš”, ì¡°íšŒìˆ˜, êµ¬ë…ì)
    video_metadata = get_video_metadata(driver)
    
    # 1. ì„¤ëª…ê¸€ ìˆ˜ì§‘ (Word2Vec í•™ìŠµì— ë§¤ìš° ì¤‘ìš”)
    desc = get_video_description(driver)
    if desc and len(desc) > 50:
        collected.append({
            "video_title": title, 
            "video_url": url, 
            "author": "Uploader(Desc)",
            "comment": desc, 
            "type": "description",
            "video_published_date": video_metadata['video_published_date'],
            "video_likes": video_metadata['video_likes'],
            "video_views": video_metadata['video_views'],
            "channel_subscribers": video_metadata['channel_subscribers'],
            "comment_date": None,  # ì„¤ëª…ê¸€ì€ ë‚ ì§œ ì—†ìŒ
            "crawled_at": datetime.now().strftime("%Y-%m-%d")
        })
    
    # 2. ëŒ“ê¸€ ìˆ˜ì§‘
    try:
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, "comments")))
    except:
        return collected
    
    driver.execute_script("window.scrollTo(0, 600);")
    random_sleep(3, 5)
    
    last_h = driver.execute_script("return document.documentElement.scrollHeight")
    while len(collected) < limit + 1:
        blocks = driver.find_elements(By.CSS_SELECTOR, 'ytd-comment-thread-renderer')
        for block in blocks:
            if len(collected) >= limit + 1: break
            try:
                text = block.find_element(By.ID, "content-text").text
                # [í’ˆì§ˆ í•„í„°] ë„ˆë¬´ ì§§ì€ ëŒ“ê¸€ ë²„ë¦¼
                if len(text) < MIN_COMMENT_LENGTH: continue
                
                try: vote = block.find_element(By.ID, "vote-count-middle").text
                except: vote = "0"
                try: author = block.find_element(By.ID, "author-text").text.strip()
                except: author = "unknown"
                
                # ëŒ“ê¸€ ì‘ì„±ì¼ ìˆ˜ì§‘
                comment_date = None
                try:
                    date_elem = block.find_element(By.CSS_SELECTOR, "#published-time-text a")
                    comment_date = date_elem.text.strip()  # "3ì£¼ ì „", "2ì¼ ì „" ë“±
                except:
                    pass
                
                collected.append({
                    "video_title": title, 
                    "video_url": url, 
                    "author": author,
                    "comment": text, 
                    "type": "comment",
                    "video_published_date": video_metadata['video_published_date'],
                    "video_likes": video_metadata['video_likes'],
                    "video_views": video_metadata['video_views'],
                    "channel_subscribers": video_metadata['channel_subscribers'],
                    "comment_date": comment_date,
                    "crawled_at": datetime.now().strftime("%Y-%m-%d")
                })
            except: continue
        
        if len(collected) >= limit + 1: break
        driver.execute_script("window.scrollBy(0, 1000);")
        time.sleep(random.uniform(1.5, 2.5))
        
        new_h = driver.execute_script("return document.documentElement.scrollHeight")
        if new_h == last_h: break
        last_h = new_h
        
    return collected

# ==========================================
# ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    # íŒŒì¼ í™•ì¸
    if "2025XXXX" in INPUT_KEYWORD_FILE:
        print("[ì£¼ì˜] INPUT_KEYWORD_FILE ë³€ìˆ˜ì— 1ë²ˆ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë§Œë“  íŒŒì¼ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        # í´ë” ë‚´ ê°€ì¥ ìµœì‹  csv íŒŒì¼ ìë™ ì°¾ê¸° (í¸ì˜ ê¸°ëŠ¥)
        try:
            files = [f for f in os.listdir('.') if f.startswith('trend_keywords_') and f.endswith('.csv')]
            if files:
                latest_file = max(files, key=os.path.getctime)
                print(f"-> ìµœì‹  íŒŒì¼ ìë™ ê°ì§€ë¨: {latest_file}")
                target_file = latest_file
            else:
                return
        except: return
    else:
        target_file = INPUT_KEYWORD_FILE

    # í‚¤ì›Œë“œ ë¡œë“œ
    try:
        df = pd.read_csv(target_file)
        keywords = df['keyword'].tolist()
        
        # í‚¤ì›Œë“œ ì¡°í•© ì—¬ë¶€ ê²°ì •
        if USE_COMBINATION:
            print(f"\n[ğŸ”§ í‚¤ì›Œë“œ ì¡°í•© ìƒì„±ì¤‘...]")
            print(f"   - ì›ë³¸ í‚¤ì›Œë“œ ê°œìˆ˜: {len(keywords)}ê°œ")
            print(f"   - ì¡°í•© í¬ê¸°: {COMBINATION_SIZE}ê°œì”©")
            
            combined_keywords = combine_keywords(
                keywords, 
                combination_size=COMBINATION_SIZE, 
                max_combinations=MAX_COMBINATIONS
            )
            
            print(f"   - ìƒì„±ëœ ì¡°í•© ê°œìˆ˜: {len(combined_keywords)}ê°œ")
            print(f"   - ì˜ˆì‹œ: {combined_keywords[:3]}")
        else:
            print(f"\n[ğŸ”§ í‚¤ì›Œë“œ ì¡°í•© OFF - ì›ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©]")
            print(f"   - í‚¤ì›Œë“œ ê°œìˆ˜: {len(keywords)}ê°œ")
            print(f"   - ì˜ˆì‹œ: {keywords[:3]}")
            combined_keywords = keywords  # ì›ë³¸ í‚¤ì›Œë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        
    except Exception as e:
        print(f"[Error] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return

    options = uc.ChromeOptions()
    options.add_argument('--no-first-run')
    options.add_argument("--mute-audio")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    
    driver = uc.Chrome(options=options)
    driver.set_page_load_timeout(30)  # 30ì´ˆ ì´ìƒ ë¡œë”©ë˜ë©´ Timeout ì—ëŸ¬ ë°œìƒ (ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    output_dir = "data/youtube"
    os.makedirs(output_dir, exist_ok=True)
    final_filename = os.path.join(output_dir, f"final_dataset_youtube_{timestamp}.csv")
    total_count = 0

    print("="*60)
    mode_text = "ì¡°í•© í‚¤ì›Œë“œ" if USE_COMBINATION else "ì›ë³¸ í‚¤ì›Œë“œ"
    print(f"ğŸ¬ ìœ íŠœë¸Œ ë§ˆì´ë‹ ì‹œì‘ ({mode_text}: {len(combined_keywords)}ê°œ)")
    print("="*60)

    try:
        for idx, kw in enumerate(combined_keywords, 1):
            print(f"\n[{idx}/{len(combined_keywords)}] í‚¤ì›Œë“œ: {kw}")
            
            video_list = get_video_links(driver, kw, VIDEOS_PER_KEYWORD)
            
            for title, link in video_list:
                data_list = get_comments_from_video(driver, title, link, COMMENTS_PER_VIDEO)
                
                # ë©”íƒ€ë°ì´í„°: ì–´ë–¤ í‚¤ì›Œë“œë¡œ ì°¾ì•˜ëŠ”ì§€ ê¸°ë¡
                for d in data_list:
                    d['search_keyword'] = kw
                
                if data_list:
                    res_df = pd.DataFrame(data_list)
                    header = not os.path.exists(final_filename)
                    res_df.to_csv(final_filename, index=False, mode='a', encoding='utf-8-sig', header=header)
                    total_count += len(data_list)
                
                random_sleep(3, 5) # ì˜ìƒ ê°„ íœ´ì‹
            
            time.sleep(5) # í‚¤ì›Œë“œ ê°„ íœ´ì‹

    finally:
        driver.quit()
        print("\n" + "="*60)
        print(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ! ì´ {total_count}ê°œ ë°ì´í„°")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {final_filename}")
        print("="*60)

if __name__ == "__main__":
    main()